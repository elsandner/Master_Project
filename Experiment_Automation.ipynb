{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Test Automation\n",
    "\n",
    "Runs Test_ML_Models_A in a loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import script_utils as mL\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "\n",
    "NDBC = mL.NDBC_lib\n",
    "ERA5 = mL.ERA5_lib\n",
    "Models = mL.Models\n",
    "DP = mL.DataProcessor\n",
    "Experiment = mL.Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def run_MLM_test(MODEL_NAME, ALPHA, filename, report_description,\n",
    "               DATAFILE = \"dataset_GOM_1_A_A.pickle\", STATIONARY_SHIFT = 1, N_TEST_HOURS=24):\n",
    "\n",
    "    #Read data from file\n",
    "    data_directory = os.path.join(os.getcwd(), f'data/datasets/type_A')\n",
    "    with open(f'data/datasets/publication/{DATAFILE}', 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    data = dataset[\"data\"]\n",
    "\n",
    "    #Preprocessing\n",
    "    data_stationary = DP.data_to_stationary(data, n = STATIONARY_SHIFT)\n",
    "    data_supervised = DP.data_to_supervised(data_stationary, n_in=3)\n",
    "\n",
    "    train_X, train_y, test_X, test_y = DP.train_test_split(data_supervised, N_TEST_HOURS)\n",
    "\n",
    "    #Training\n",
    "    start_time = time.time()\n",
    "    model = Models.get_model(MODEL_NAME, train_X, train_y, ALPHA)\n",
    "    TRAINING_TIME = time.time() - start_time\n",
    "\n",
    "    #One-Shot-Forecasting\n",
    "    model.predict(train_X, batch_size=1)\n",
    "    yhat = model.predict(test_X)\n",
    "\n",
    "    #Create Evaluation Dataframes\n",
    "    output_cols = data.columns.tolist()\n",
    "    yhat_df = pd.DataFrame(yhat, columns=[name + \"_pred\" for name in output_cols])\n",
    "    yhat_df.set_index(data.tail(len(yhat)).index, inplace=True)\n",
    "\n",
    "    evaluation_1 = data.tail(len(yhat)+1).copy()  #+1 since i need that value for de-differencing\n",
    "\n",
    "    #De-Differenciating\n",
    "    for col in evaluation_1.columns:\n",
    "        evaluation_1[f\"{col}_pred\"]= evaluation_1[col].shift(STATIONARY_SHIFT) + yhat_df[f\"{col}_pred\"]\n",
    "\n",
    "    evaluation_1 = evaluation_1.iloc[STATIONARY_SHIFT:]  # remove first n entries since there is no delta value for them\n",
    "\n",
    "    # Correct wind direction (modulo 360)\n",
    "    wdir_columns = [col for col in evaluation_1.columns if col.startswith(\"WDIR\")]\n",
    "    evaluation_1[wdir_columns] = evaluation_1[wdir_columns] % 360\n",
    "\n",
    "    #CREATE REPORT\n",
    "    # Convert model summary to string\n",
    "    stringlist = []\n",
    "    model.summary(print_fn=lambda x: stringlist.append(x))\n",
    "    model_summary = \"\\n\".join(stringlist)\n",
    "\n",
    "    report = Experiment(\n",
    "        name=filename,\n",
    "        description=report_description,\n",
    "\n",
    "        stations = dataset[\"stations\"],\n",
    "        years = dataset[\"years\"],\n",
    "        nan_threshold=dataset[\"nan_threshold\"],\n",
    "        features=dataset[\"features\"],\n",
    "        era5=dataset[\"add_era5\"],\n",
    "\n",
    "        stationary_shift=STATIONARY_SHIFT,\n",
    "\n",
    "        n_test_hours=N_TEST_HOURS,\n",
    "\n",
    "        #stationary=STATIONARY,\n",
    "        scaler= None, # SCALER,\n",
    "\n",
    "        model_name = MODEL_NAME,\n",
    "        model_summary=model_summary,\n",
    "        training_time = TRAINING_TIME,\n",
    "\n",
    "        one_shot_forecast = evaluation_1,\n",
    "        recursive_forecast = None   # evaluation_2\n",
    "    )\n",
    "\n",
    "\n",
    "    # open a file for writing in binary mode\n",
    "    filepath = f'data/reports/{report.name}.pickle'\n",
    "    with open(filepath, 'wb') as f:\n",
    "        # write the object to the file using pickle.dump()\n",
    "        pickle.dump(report, f)\n",
    "        print(f\"File successfully saved:{filepath}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def run_SSUM_test(MODEL_NAME, ALPHA, filename, report_description,\n",
    "               DATAFILE = \"GOM_buoys_since2002_SSUM.pickle\", STATIONARY_SHIFT = 1, N_TEST_HOURS=24):   #nan_threshold=0.66 (original): type_B/dataset_GOM_1_B_B.pickle    #current version is modification from september 5th - it uses the dataset SSUM/GOM_buoys_since2002_SSUM.pickle with nan rate of 0.33\n",
    "\n",
    "    #Read data from file\n",
    "    with open(f'data/datasets/SSUM/{DATAFILE}', 'rb') as f:\n",
    "        # load the object from the file using pickle.load()\n",
    "        dataset = pickle.load(f)\n",
    "\n",
    "    train = dataset[\"data_train\"]\n",
    "    test = dataset[\"data_test\"]\n",
    "\n",
    "    #Preprocessing\n",
    "    train_stationary = DP.data_to_stationary(train, n = STATIONARY_SHIFT)\n",
    "    test_stationary = DP.data_to_stationary(test, n = STATIONARY_SHIFT)\n",
    "\n",
    "    #Data is already supervised!\n",
    "\n",
    "    train_X, train_y, _, _ = DP.train_test_split(train_stationary, -len(train_stationary))\n",
    "    _, _, test_X, test_y = DP.train_test_split(test_stationary, len(test_stationary))\n",
    "\n",
    "    #Training\n",
    "    start_time = time.time()\n",
    "    model = Models.get_model(MODEL_NAME, train_X, train_y, ALPHA)\n",
    "    TRAINING_TIME = time.time() - start_time\n",
    "\n",
    "    #One-Shot-Forecasting\n",
    "    model.predict(train_X, batch_size=1)\n",
    "    yhat = model.predict(test_X)\n",
    "\n",
    "    #Create Evaluation Dataframes\n",
    "    output_cols  = test.loc[:, ~test.columns.str.contains('t-')].columns\n",
    "\n",
    "    yhat_df = pd.DataFrame(yhat)\n",
    "    yhat_df.columns = [name + \"_pred\" for name in output_cols]\n",
    "    yhat_df.set_index(test.tail(len(yhat)).index, inplace=True)\n",
    "    evaluation_1 = test.loc[:, ~test.columns.str.contains('t-')]    #ground truth: just y, without X\n",
    "\n",
    "    #De-Differenciating\n",
    "    for col in evaluation_1.columns:\n",
    "        shifted = evaluation_1[col].shift(STATIONARY_SHIFT)\n",
    "        evaluation_1[f\"{col}_pred\"]= shifted + yhat_df[f\"{col}_pred\"]\n",
    "\n",
    "    evaluation_1 = evaluation_1.iloc[STATIONARY_SHIFT:]  # remove first n entries since there is no delta value for them\n",
    "\n",
    "    # Correct wind direction (modulo 360)\n",
    "    wdir_columns = [col for col in evaluation_1.columns if col.startswith(\"WDIR\")]\n",
    "    evaluation_1[wdir_columns] = evaluation_1[wdir_columns] % 360\n",
    "\n",
    "    #CREATE REPORT\n",
    "    #Convert model summary to string\n",
    "    stringlist = []\n",
    "    model.summary(print_fn=lambda x: stringlist.append(x))\n",
    "    model_summary = \"\\n\".join(stringlist)\n",
    "\n",
    "    report = Experiment(\n",
    "            name=filename,\n",
    "            description=report_description,\n",
    "\n",
    "            stations = dataset[\"files\"],\n",
    "            years = [\"not available\"],\n",
    "            nan_threshold=dataset[\"nan_threshold\"],\n",
    "            features=dataset[\"features\"],\n",
    "            era5=dataset[\"add_era5\"],\n",
    "\n",
    "            stationary_shift=STATIONARY_SHIFT,\n",
    "            # lag=1,\n",
    "            n_test_hours=dataset[\"num_test_hours\"],\n",
    "\n",
    "            #stationary=STATIONARY,\n",
    "            scaler= None, # SCALER,\n",
    "\n",
    "            model_name = MODEL_NAME,\n",
    "            model_summary=model_summary,\n",
    "            training_time = TRAINING_TIME,\n",
    "\n",
    "            one_shot_forecast = evaluation_1,\n",
    "            recursive_forecast = None\n",
    "    )\n",
    "\n",
    "    # open a file for writing in binary mode\n",
    "    filepath = f'data/reports/{filename}.pickle'\n",
    "    with open(filepath, 'wb') as f:\n",
    "        # write the object to the file using pickle.dump()\n",
    "        pickle.dump(report, f)\n",
    "        print(\"File successfully saved:\")\n",
    "        print(filepath)\n",
    "\n",
    "\n",
    "    #Release Data Variables to reduce RAM usage\n",
    "    del train\n",
    "    del test\n",
    "    del train_stationary\n",
    "    del test_stationary\n",
    "    del train_X\n",
    "    del train_y\n",
    "    del test_X\n",
    "    del test_y\n",
    "    del model\n",
    "    del yhat\n",
    "    del stringlist\n",
    "    del model_summary\n",
    "    del filepath\n",
    "    del report\n",
    "    gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Execute All Tests:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datafile =\"GOM_stage_2.pickle\"\n",
    "approach = \"MLM\"   # \"MLM\" ... Multi Location Modelling, \"SSUD\" ... Station Specific Unified Dataset\n",
    "model_names = [\"transformer\", \"LSTM_2\", \"CNN_2\"] # [\"GRU\", \"CNN\", \"TCN\"]\n",
    "alpha_values = np.arange(0.0, 1.1, 0.1) #from, to, increment\n",
    "report_description = \"Executed with automated script. With random seed. used shrinked dataset stage 1\"\n",
    "\n",
    "print(alpha_values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started transformer - 0.0\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m             \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarted \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m - \u001B[39m\u001B[38;5;132;01m{\u001B[39;00malpha\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m             filename \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreport_A_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mformat\u001B[39m(alpha, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.1f\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 6\u001B[0m             \u001B[43mrun_MLM_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43mreport_description\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDATAFILE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdatafile\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m approach \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSSUD\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m model \u001B[38;5;129;01min\u001B[39;00m model_names:\n",
      "Cell \u001B[0;32mIn[7], line 18\u001B[0m, in \u001B[0;36mrun_MLM_test\u001B[0;34m(MODEL_NAME, ALPHA, filename, report_description, DATAFILE, STATIONARY_SHIFT, N_TEST_HOURS)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m#Training\u001B[39;00m\n\u001B[1;32m     17\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m---> 18\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mModels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMODEL_NAME\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_X\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mALPHA\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m TRAINING_TIME \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m#One-Shot-Forecasting\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Uni/WS22/Master Thesis/Master_Project/script_utils.py:1784\u001B[0m, in \u001B[0;36mModels.get_model\u001B[0;34m(model_name, train_X, train_y, alpha)\u001B[0m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m   1782\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_model\u001B[39m(model_name, train_X, train_y, alpha):\n\u001B[1;32m   1783\u001B[0m     model_function \u001B[38;5;241m=\u001B[39m Models\u001B[38;5;241m.\u001B[39mmodel_dictionary[model_name]\n\u001B[0;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_X\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Uni/WS22/Master Thesis/Master_Project/script_utils.py:1763\u001B[0m, in \u001B[0;36mModels.transformer\u001B[0;34m(train_X, train_y, alpha)\u001B[0m\n\u001B[1;32m   1760\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m=\u001B[39mcustom_loss())\n\u001B[1;32m   1762\u001B[0m \u001B[38;5;66;03m# fit network\u001B[39;00m\n\u001B[0;32m-> 1763\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_X\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1764\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1766\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/keras/engine/training.py:1650\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1642\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1643\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1644\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1647\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1648\u001B[0m ):\n\u001B[1;32m   1649\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1650\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1651\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1652\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    877\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    879\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 880\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    882\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    883\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:945\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    941\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# Fall through to cond-based initialization.\u001B[39;00m\n\u001B[1;32m    942\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    943\u001B[0m     \u001B[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001B[39;00m\n\u001B[1;32m    944\u001B[0m     \u001B[38;5;66;03m# no_variable_creation function.\u001B[39;00m\n\u001B[0;32m--> 945\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    946\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    947\u001B[0m   _, _, filtered_flat_args \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    948\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn\u001B[38;5;241m.\u001B[39m_function_spec  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    949\u001B[0m       \u001B[38;5;241m.\u001B[39mcanonicalize_function_inputs(\n\u001B[1;32m    950\u001B[0m           args, kwds))\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    132\u001B[0m   (concrete_function,\n\u001B[1;32m    133\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m--> 134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1741\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1743\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1744\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1745\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1746\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1747\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1748\u001B[0m     args,\n\u001B[1;32m   1749\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1750\u001B[0m     executing_eagerly)\n\u001B[1;32m   1751\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    377\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 378\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    380\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    381\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    384\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    385\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    386\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    387\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    390\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    391\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if approach == \"MLM\":\n",
    "    for model in model_names:\n",
    "        for alpha in alpha_values:\n",
    "            print(f\"Started {model} - {alpha}\")\n",
    "            filename = f'report_A_{model}_{format(alpha, \".1f\")}'\n",
    "            run_MLM_test(model,alpha,filename,report_description, DATAFILE = datafile)\n",
    "\n",
    "elif approach == \"SSUD\":\n",
    "    for model in model_names:\n",
    "        for alpha in alpha_values:\n",
    "            filename = f'report_B_{model}_{format(alpha, \".1f\")}'\n",
    "            run_SSUM_test(model,alpha,filename,report_description)\n",
    "            print(filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"DONE\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Execute specific tests:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2589/2589 [==============================] - 22s 8ms/step - loss: 1.9524 - val_loss: 3.8861\n",
      "Epoch 2/100\n",
      "2589/2589 [==============================] - 27s 10ms/step - loss: 1.9429 - val_loss: 3.8564\n",
      "Epoch 3/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.9372 - val_loss: 3.8416\n",
      "Epoch 4/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.9315 - val_loss: 3.8273\n",
      "Epoch 5/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.9271 - val_loss: 3.8149\n",
      "Epoch 6/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.9170 - val_loss: 3.7964\n",
      "Epoch 7/100\n",
      "2589/2589 [==============================] - 19s 7ms/step - loss: 1.9087 - val_loss: 3.7893\n",
      "Epoch 8/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.9033 - val_loss: 3.7846\n",
      "Epoch 9/100\n",
      "2589/2589 [==============================] - 17s 6ms/step - loss: 1.8987 - val_loss: 3.7833\n",
      "Epoch 10/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.8947 - val_loss: 3.7822\n",
      "Epoch 11/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8917 - val_loss: 3.7849\n",
      "Epoch 12/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8882 - val_loss: 3.7779\n",
      "Epoch 13/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8847 - val_loss: 3.7823\n",
      "Epoch 14/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8817 - val_loss: 3.7820\n",
      "Epoch 15/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8784 - val_loss: 3.7894\n",
      "Epoch 16/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8749 - val_loss: 3.7886\n",
      "Epoch 17/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8729 - val_loss: 3.7855\n",
      "Epoch 18/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8703 - val_loss: 3.7951\n",
      "Epoch 19/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8670 - val_loss: 3.7892\n",
      "Epoch 20/100\n",
      "2589/2589 [==============================] - 21s 8ms/step - loss: 1.8654 - val_loss: 3.7942\n",
      "Epoch 21/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8630 - val_loss: 3.7971\n",
      "Epoch 22/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8601 - val_loss: 3.7924\n",
      "Epoch 23/100\n",
      "2589/2589 [==============================] - 17s 6ms/step - loss: 1.8572 - val_loss: 3.8013\n",
      "Epoch 24/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8548 - val_loss: 3.8033\n",
      "Epoch 25/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8513 - val_loss: 3.8027\n",
      "Epoch 26/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8508 - val_loss: 3.8096\n",
      "Epoch 27/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8483 - val_loss: 3.8073\n",
      "Epoch 28/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8453 - val_loss: 3.8138\n",
      "Epoch 29/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8437 - val_loss: 3.8094\n",
      "Epoch 30/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8416 - val_loss: 3.8086\n",
      "Epoch 31/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8400 - val_loss: 3.8159\n",
      "Epoch 32/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8389 - val_loss: 3.8192\n",
      "Epoch 33/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8354 - val_loss: 3.8150\n",
      "Epoch 34/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8336 - val_loss: 3.8193\n",
      "Epoch 35/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8326 - val_loss: 3.8165\n",
      "Epoch 36/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8303 - val_loss: 3.8272\n",
      "Epoch 37/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.8287 - val_loss: 3.8263\n",
      "Epoch 38/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.8270 - val_loss: 3.8201\n",
      "Epoch 39/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.8263 - val_loss: 3.8264\n",
      "Epoch 40/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.8258 - val_loss: 3.8246\n",
      "Epoch 41/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.8237 - val_loss: 3.8296\n",
      "Epoch 42/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8213 - val_loss: 3.8314\n",
      "Epoch 43/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.8198 - val_loss: 3.8353\n",
      "Epoch 44/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8169 - val_loss: 3.8290\n",
      "Epoch 45/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8167 - val_loss: 3.8316\n",
      "Epoch 46/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.8163 - val_loss: 3.8339\n",
      "Epoch 47/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8142 - val_loss: 3.8371\n",
      "Epoch 48/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8146 - val_loss: 3.8241\n",
      "Epoch 49/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8110 - val_loss: 3.8254\n",
      "Epoch 50/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8109 - val_loss: 3.8353\n",
      "Epoch 51/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8090 - val_loss: 3.8351\n",
      "Epoch 52/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8081 - val_loss: 3.8384\n",
      "Epoch 53/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8064 - val_loss: 3.8354\n",
      "Epoch 54/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8059 - val_loss: 3.8338\n",
      "Epoch 55/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.8050 - val_loss: 3.8432\n",
      "Epoch 56/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.8022 - val_loss: 3.8341\n",
      "Epoch 57/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7999 - val_loss: 3.8457\n",
      "Epoch 58/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7989 - val_loss: 3.8367\n",
      "Epoch 59/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7988 - val_loss: 3.8473\n",
      "Epoch 60/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7980 - val_loss: 3.8355\n",
      "Epoch 61/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7969 - val_loss: 3.8287\n",
      "Epoch 62/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7975 - val_loss: 3.8330\n",
      "Epoch 63/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7969 - val_loss: 3.8441\n",
      "Epoch 64/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7960 - val_loss: 3.8432\n",
      "Epoch 65/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7930 - val_loss: 3.8496\n",
      "Epoch 66/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.7905 - val_loss: 3.8358\n",
      "Epoch 67/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.7927 - val_loss: 3.8516\n",
      "Epoch 68/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7911 - val_loss: 3.8259\n",
      "Epoch 69/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.7913 - val_loss: 3.8475\n",
      "Epoch 70/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7883 - val_loss: 3.8458\n",
      "Epoch 71/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7888 - val_loss: 3.8378\n",
      "Epoch 72/100\n",
      "2589/2589 [==============================] - 3121s 1s/step - loss: 1.7866 - val_loss: 3.8423\n",
      "Epoch 73/100\n",
      "2589/2589 [==============================] - 1695s 655ms/step - loss: 1.7840 - val_loss: 3.8473\n",
      "Epoch 74/100\n",
      "2589/2589 [==============================] - 2947s 1s/step - loss: 1.7846 - val_loss: 3.8580\n",
      "Epoch 75/100\n",
      "2589/2589 [==============================] - 794s 307ms/step - loss: 1.7839 - val_loss: 3.8613\n",
      "Epoch 76/100\n",
      "2589/2589 [==============================] - 3018s 1s/step - loss: 1.7854 - val_loss: 3.8613\n",
      "Epoch 77/100\n",
      "2589/2589 [==============================] - 3097s 1s/step - loss: 1.7818 - val_loss: 3.8607\n",
      "Epoch 78/100\n",
      "2589/2589 [==============================] - 2634s 1s/step - loss: 1.7829 - val_loss: 3.8554\n",
      "Epoch 79/100\n",
      "2589/2589 [==============================] - 173s 67ms/step - loss: 1.7796 - val_loss: 3.8514\n",
      "Epoch 80/100\n",
      "2589/2589 [==============================] - 2980s 1s/step - loss: 1.7802 - val_loss: 3.8454\n",
      "Epoch 81/100\n",
      "2589/2589 [==============================] - 309s 119ms/step - loss: 1.7765 - val_loss: 3.8618\n",
      "Epoch 82/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.7767 - val_loss: 3.8552\n",
      "Epoch 83/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.7770 - val_loss: 3.8510\n",
      "Epoch 84/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.7754 - val_loss: 3.8632\n",
      "Epoch 85/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.7767 - val_loss: 3.8722\n",
      "Epoch 86/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.7758 - val_loss: 3.8547\n",
      "Epoch 87/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.7752 - val_loss: 3.8604\n",
      "Epoch 88/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7740 - val_loss: 3.8629\n",
      "Epoch 89/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.7732 - val_loss: 3.8660\n",
      "Epoch 90/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7742 - val_loss: 3.8583\n",
      "Epoch 91/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.7730 - val_loss: 3.8739\n",
      "Epoch 92/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.7705 - val_loss: 3.8555\n",
      "Epoch 93/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.7679 - val_loss: 3.8520\n",
      "Epoch 94/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7698 - val_loss: 3.8517\n",
      "Epoch 95/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7679 - val_loss: 3.8744\n",
      "Epoch 96/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7691 - val_loss: 3.8659\n",
      "Epoch 97/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.7686 - val_loss: 3.8599\n",
      "Epoch 98/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.7694 - val_loss: 3.8577\n",
      "Epoch 99/100\n",
      "2589/2589 [==============================] - 17s 7ms/step - loss: 1.7657 - val_loss: 3.8594\n",
      "Epoch 100/100\n",
      "2589/2589 [==============================] - 18s 7ms/step - loss: 1.7672 - val_loss: 3.8563\n",
      "184052/184052 [==============================] - 121s 653us/step\n",
      "1/1 [==============================] - 0s 454ms/step\n",
      "File successfully saved:data/reports/report_A_LSTM_2_0.7.pickle\n",
      "Epoch 1/100\n",
      "2589/2589 [==============================] - 3s 1ms/step - loss: 1.9692 - val_loss: 3.8876\n",
      "Epoch 2/100\n",
      "2589/2589 [==============================] - 3s 972us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 3/100\n",
      "2589/2589 [==============================] - 3s 970us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 4/100\n",
      "2589/2589 [==============================] - 2s 942us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 5/100\n",
      "2589/2589 [==============================] - 2s 929us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 6/100\n",
      "2589/2589 [==============================] - 3s 1ms/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 7/100\n",
      "2589/2589 [==============================] - 2s 923us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 8/100\n",
      "2589/2589 [==============================] - 2s 952us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 9/100\n",
      "2589/2589 [==============================] - 2s 917us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 10/100\n",
      "2589/2589 [==============================] - 2s 925us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 11/100\n",
      "2589/2589 [==============================] - 3s 979us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 12/100\n",
      "2589/2589 [==============================] - 3s 968us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 13/100\n",
      "2589/2589 [==============================] - 2s 947us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 14/100\n",
      "2589/2589 [==============================] - 2s 910us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 15/100\n",
      "2589/2589 [==============================] - 2s 905us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 16/100\n",
      "2589/2589 [==============================] - 2s 910us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 17/100\n",
      "2589/2589 [==============================] - 2s 903us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 18/100\n",
      "2589/2589 [==============================] - 2s 903us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 19/100\n",
      "2589/2589 [==============================] - 2s 901us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 20/100\n",
      "2589/2589 [==============================] - 2s 904us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 21/100\n",
      "2589/2589 [==============================] - 2s 900us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 22/100\n",
      "2589/2589 [==============================] - 2s 901us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 23/100\n",
      "2589/2589 [==============================] - 2s 898us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 24/100\n",
      "2589/2589 [==============================] - 2s 940us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 25/100\n",
      "2589/2589 [==============================] - 2s 927us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 26/100\n",
      "2589/2589 [==============================] - 2s 922us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 27/100\n",
      "2589/2589 [==============================] - 2s 899us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 28/100\n",
      "2589/2589 [==============================] - 2s 899us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 29/100\n",
      "2589/2589 [==============================] - 2s 901us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 30/100\n",
      "2589/2589 [==============================] - 2s 905us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 31/100\n",
      "2589/2589 [==============================] - 2s 899us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 32/100\n",
      "2589/2589 [==============================] - 2s 895us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 33/100\n",
      "2589/2589 [==============================] - 2s 898us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 34/100\n",
      "2589/2589 [==============================] - 2s 899us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 35/100\n",
      "2589/2589 [==============================] - 2s 898us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 36/100\n",
      "2589/2589 [==============================] - 2s 913us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 37/100\n",
      "2589/2589 [==============================] - 2s 937us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 38/100\n",
      "2589/2589 [==============================] - 2s 932us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 39/100\n",
      "2589/2589 [==============================] - 3s 980us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 40/100\n",
      "2589/2589 [==============================] - 2s 908us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 41/100\n",
      "2589/2589 [==============================] - 2s 900us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 42/100\n",
      "2589/2589 [==============================] - 2s 904us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 43/100\n",
      "2589/2589 [==============================] - 2s 902us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 44/100\n",
      "2589/2589 [==============================] - 2s 899us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 45/100\n",
      "2589/2589 [==============================] - 2s 900us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 46/100\n",
      "2589/2589 [==============================] - 2s 903us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 47/100\n",
      "2589/2589 [==============================] - 2s 902us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 48/100\n",
      "2589/2589 [==============================] - 2s 904us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 49/100\n",
      "2589/2589 [==============================] - 2s 924us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 50/100\n",
      "2589/2589 [==============================] - 2s 936us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 51/100\n",
      "2589/2589 [==============================] - 2s 935us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 52/100\n",
      "2589/2589 [==============================] - 2s 910us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 53/100\n",
      "2589/2589 [==============================] - 2s 902us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 54/100\n",
      "2589/2589 [==============================] - 2s 900us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 55/100\n",
      "2589/2589 [==============================] - 2s 903us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 56/100\n",
      "2589/2589 [==============================] - 2s 904us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 57/100\n",
      "2589/2589 [==============================] - 2s 900us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 58/100\n",
      "2589/2589 [==============================] - 2s 896us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 59/100\n",
      "2589/2589 [==============================] - 2s 901us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 60/100\n",
      "2589/2589 [==============================] - 2s 899us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 61/100\n",
      "2589/2589 [==============================] - 2s 898us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 62/100\n",
      "2589/2589 [==============================] - 2s 933us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 63/100\n",
      "2589/2589 [==============================] - 2s 943us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 64/100\n",
      "2589/2589 [==============================] - 2s 940us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 65/100\n",
      "2589/2589 [==============================] - 2s 901us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 66/100\n",
      "2589/2589 [==============================] - 2s 904us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 67/100\n",
      "2589/2589 [==============================] - 2s 901us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 68/100\n",
      "2589/2589 [==============================] - 2s 900us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 69/100\n",
      "2589/2589 [==============================] - 2s 909us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 70/100\n",
      "2589/2589 [==============================] - 2s 900us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 71/100\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 72/100\n",
      "2589/2589 [==============================] - 3s 1ms/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 73/100\n",
      "2589/2589 [==============================] - 3s 971us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 74/100\n",
      "2589/2589 [==============================] - 3s 1ms/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 75/100\n",
      "2589/2589 [==============================] - 2s 935us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 76/100\n",
      "2589/2589 [==============================] - 7s 3ms/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 77/100\n",
      "2589/2589 [==============================] - 2s 930us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 78/100\n",
      "2589/2589 [==============================] - 2s 927us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 79/100\n",
      "2589/2589 [==============================] - 2s 924us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 80/100\n",
      "2589/2589 [==============================] - 2s 932us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 81/100\n",
      "2589/2589 [==============================] - 117s 45ms/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 82/100\n",
      "2589/2589 [==============================] - 4s 1ms/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 83/100\n",
      "2589/2589 [==============================] - 3s 1ms/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 84/100\n",
      "2589/2589 [==============================] - 2s 920us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 85/100\n",
      "2589/2589 [==============================] - 3s 1ms/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 86/100\n",
      "2589/2589 [==============================] - 2s 880us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 87/100\n",
      "2589/2589 [==============================] - 2s 863us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 88/100\n",
      "2589/2589 [==============================] - 2s 883us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 89/100\n",
      "2589/2589 [==============================] - 2s 874us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 90/100\n",
      "2589/2589 [==============================] - 191s 74ms/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 91/100\n",
      "2589/2589 [==============================] - 3s 1ms/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 92/100\n",
      "2589/2589 [==============================] - 2s 833us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 93/100\n",
      "2589/2589 [==============================] - 2s 821us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 94/100\n",
      "2589/2589 [==============================] - 3s 1ms/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 95/100\n",
      "2589/2589 [==============================] - 2s 847us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 96/100\n",
      "2589/2589 [==============================] - 243s 94ms/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 97/100\n",
      "2589/2589 [==============================] - 3s 1ms/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 98/100\n",
      "2589/2589 [==============================] - 3s 1ms/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 99/100\n",
      "2589/2589 [==============================] - 2s 927us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "Epoch 100/100\n",
      "2589/2589 [==============================] - 2s 900us/step - loss: 1.9584 - val_loss: 3.8876\n",
      "184052/184052 [==============================] - 54s 294us/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "File successfully saved:data/reports/report_A_CNN_2_0.2.pickle\n",
      "Epoch 1/100\n",
      "2589/2589 [==============================] - 38s 14ms/step - loss: 1.9752 - val_loss: 3.8853\n",
      "Epoch 2/100\n",
      "2589/2589 [==============================] - 35s 14ms/step - loss: 1.9581 - val_loss: 3.8877\n",
      "Epoch 3/100\n",
      "2589/2589 [==============================] - 35s 14ms/step - loss: 1.9584 - val_loss: 3.8910\n",
      "Epoch 4/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9575 - val_loss: 3.8866\n",
      "Epoch 5/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9547 - val_loss: 3.8897\n",
      "Epoch 6/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9562 - val_loss: 3.8902\n",
      "Epoch 7/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9576 - val_loss: 3.8869\n",
      "Epoch 8/100\n",
      "2589/2589 [==============================] - 38s 15ms/step - loss: 1.9561 - val_loss: 3.8894\n",
      "Epoch 9/100\n",
      "2589/2589 [==============================] - 37s 14ms/step - loss: 1.9545 - val_loss: 3.8902\n",
      "Epoch 10/100\n",
      "2589/2589 [==============================] - 37s 14ms/step - loss: 1.9544 - val_loss: 3.8870\n",
      "Epoch 11/100\n",
      "2589/2589 [==============================] - 37s 14ms/step - loss: 1.9540 - val_loss: 3.8878\n",
      "Epoch 12/100\n",
      "2589/2589 [==============================] - 37s 14ms/step - loss: 1.9551 - val_loss: 3.8876\n",
      "Epoch 13/100\n",
      "2589/2589 [==============================] - 38s 15ms/step - loss: 1.9545 - val_loss: 3.8859\n",
      "Epoch 14/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9559 - val_loss: 3.8823\n",
      "Epoch 15/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9566 - val_loss: 3.8850\n",
      "Epoch 16/100\n",
      "2589/2589 [==============================] - 35s 14ms/step - loss: 1.9572 - val_loss: 3.8869\n",
      "Epoch 17/100\n",
      "2589/2589 [==============================] - 35s 14ms/step - loss: 1.9553 - val_loss: 3.8819\n",
      "Epoch 18/100\n",
      "2589/2589 [==============================] - 35s 14ms/step - loss: 1.9549 - val_loss: 3.8862\n",
      "Epoch 19/100\n",
      "2589/2589 [==============================] - 35s 14ms/step - loss: 1.9543 - val_loss: 3.8846\n",
      "Epoch 20/100\n",
      "2589/2589 [==============================] - 35s 14ms/step - loss: 1.9565 - val_loss: 3.8824\n",
      "Epoch 21/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9550 - val_loss: 3.8847\n",
      "Epoch 22/100\n",
      "2589/2589 [==============================] - 35s 14ms/step - loss: 1.9559 - val_loss: 3.8857\n",
      "Epoch 23/100\n",
      "2589/2589 [==============================] - 35s 14ms/step - loss: 1.9545 - val_loss: 3.8800\n",
      "Epoch 24/100\n",
      "2589/2589 [==============================] - 35s 14ms/step - loss: 1.9549 - val_loss: 3.8819\n",
      "Epoch 25/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9547 - val_loss: 3.8901\n",
      "Epoch 26/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9564 - val_loss: 3.8876\n",
      "Epoch 27/100\n",
      "2589/2589 [==============================] - 37s 14ms/step - loss: 1.9540 - val_loss: 3.8833\n",
      "Epoch 28/100\n",
      "2589/2589 [==============================] - 37s 14ms/step - loss: 1.9537 - val_loss: 3.8827\n",
      "Epoch 29/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9543 - val_loss: 3.8875\n",
      "Epoch 30/100\n",
      "2589/2589 [==============================] - 37s 14ms/step - loss: 1.9542 - val_loss: 3.8836\n",
      "Epoch 31/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9555 - val_loss: 3.8875\n",
      "Epoch 32/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9564 - val_loss: 3.8882\n",
      "Epoch 33/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9577 - val_loss: 3.8883\n",
      "Epoch 34/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9577 - val_loss: 3.8879\n",
      "Epoch 35/100\n",
      "2589/2589 [==============================] - 37s 14ms/step - loss: 1.9564 - val_loss: 3.8895\n",
      "Epoch 36/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9571 - val_loss: 3.8861\n",
      "Epoch 37/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9559 - val_loss: 3.8872\n",
      "Epoch 38/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9556 - val_loss: 3.8807\n",
      "Epoch 39/100\n",
      "2589/2589 [==============================] - 37s 14ms/step - loss: 1.9551 - val_loss: 3.8856\n",
      "Epoch 40/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9559 - val_loss: 3.8875\n",
      "Epoch 41/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9575 - val_loss: 3.8877\n",
      "Epoch 42/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9560 - val_loss: 3.8737\n",
      "Epoch 43/100\n",
      "2589/2589 [==============================] - 37s 14ms/step - loss: 1.9535 - val_loss: 3.8724\n",
      "Epoch 44/100\n",
      "2589/2589 [==============================] - 37s 14ms/step - loss: 1.9536 - val_loss: 3.8805\n",
      "Epoch 45/100\n",
      "2589/2589 [==============================] - 37s 14ms/step - loss: 1.9533 - val_loss: 3.8797\n",
      "Epoch 46/100\n",
      "2589/2589 [==============================] - 37s 14ms/step - loss: 1.9533 - val_loss: 3.8818\n",
      "Epoch 47/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9540 - val_loss: 3.8820\n",
      "Epoch 48/100\n",
      "2589/2589 [==============================] - 36s 14ms/step - loss: 1.9536 - val_loss: 3.8762\n",
      "Epoch 49/100\n",
      "2589/2589 [==============================] - 37s 14ms/step - loss: 1.9540 - val_loss: 3.8784\n",
      "Epoch 50/100\n",
      "1843/2589 [====================>.........] - ETA: 10s - loss: 1.8717"
     ]
    }
   ],
   "source": [
    "datafile =\"GOM_stage_1.pickle\"\n",
    "\n",
    "experiment = [[\"LSTM_2\",        0.7,    \"report_A_LSTM_2_0.7\"],\n",
    "             [\"CNN_2\",          0.2,    \"report_A_CNN_2_0.2\"],\n",
    "             [\"transformer\",    0.2,    \"report_A_transformer_0.2\"],\n",
    "            ]\n",
    "\n",
    "report_description = \"Executed selected tests with stage_2 dataset and random seed!\"\n",
    "\n",
    "for e in experiment:\n",
    "    model = e[0]\n",
    "    alpha = e[1]\n",
    "    filename = e[2]\n",
    "\n",
    "    run_MLM_test(model,alpha,filename,report_description, DATAFILE = datafile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}