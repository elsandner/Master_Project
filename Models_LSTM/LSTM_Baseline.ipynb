{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/\n",
    "\n",
    "## One-Step univariate time series forecast"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# univariate data preparation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import myLibrary as mL\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "STATION_ID = \"42036\"    # 33.61% NaN values -> Best value for GOM and 2022\n",
    "YEAR = \"2022\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from disc\n"
     ]
    }
   ],
   "source": [
    "data = mL.get_buoy_data(STATION_ID, YEAR)\n",
    "\n",
    "data = data.drop([\n",
    "    \"WDIR_42036\",\n",
    "    \"WSPD_42036\",\n",
    "    \"WVHT_42036\",\n",
    "    \"APD_42036\",\n",
    "    \"MWD_42036\",\n",
    "    \"PRES_42036\",\n",
    "    \"ATMP_42036\",\n",
    "    #\"WTMP_42036\",\n",
    "    \"DEWP_42036\"], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "NaN values:  57\n",
      "Remaining NaN values:  0\n"
     ]
    }
   ],
   "source": [
    "print(type(data))\n",
    "print(\"NaN values: \", data.isna().sum().sum())\n",
    "data.fillna(method='ffill', inplace=True) #ffill .. forward fill (just copy previous value)\n",
    "print(\"Remaining NaN values: \", data.isna().sum().sum())\n",
    "# msno.matrix(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([23. , 23. , 23. , ..., 22.1, 22.2, 22.3])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_values = data.WTMP_42036.values\n",
    "print(type(raw_values))\n",
    "raw_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transform Time Series to Stationary\n",
    "\n",
    "= Preprocessing step that converts the absolute values to delta values. This should result in a more skillful forecast.\n",
    "\n",
    "TODO: Test without this step is needed to compare if it really increases the result!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# create a differenced series\n",
    "# method expects the parameter dataset to be a pd.series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return pd.Series(diff)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# invert diferenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0       0.0\n1       0.0\n2       0.0\n3       0.0\n4       0.0\n       ... \n8754    0.0\n8755    0.0\n8756    0.1\n8757    0.1\n8758    0.1\nLength: 8759, dtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_series = difference(raw_values)\n",
    "diff_series"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tranform to supervised Learning problem\n",
    "\n",
    "LSTM model expects data devided into input (X) and output (y). The model learns a function that maps an input X to an output y. In this example, X is the observation at timestep t-1 and y is the value at t.\n",
    "\n",
    "#TODO: consider using a series of n previous timesteps as input X."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    " df = pd.DataFrame(data)\n",
    " columns = [df.shift(i) for i in range(1, lag+1)]\n",
    " columns.append(df)\n",
    " df = pd.concat(columns, axis=1)\n",
    " df.fillna(0, inplace=True)\n",
    " return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0. , 0. ],\n       [0. , 0. ],\n       [0. , 0. ],\n       ...,\n       [0. , 0.1],\n       [0.1, 0.1],\n       [0.1, 0.1]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised = timeseries_to_supervised(diff_series, 1)\n",
    "supervised_values = supervised.values\n",
    "supervised_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train / Test split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "test_hours = 7*24 #one week forecast\n",
    "\n",
    "# split the dataframe into training and testing subsets\n",
    "train, test = supervised_values[0:-test_hours], supervised_values[-test_hours:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       ...,\n       [ 0.1, -0.1],\n       [-0.1,  0. ],\n       [ 0. , -0.1]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.1,  0.1],\n       [ 0.1,  0. ],\n       [ 0. , -0.1],\n       [-0.1,  0. ],\n       [ 0. , -0.1],\n       [-0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. , -0.1],\n       [-0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. , -0.1],\n       [-0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. , -0.1],\n       [-0.1,  0. ],\n       [ 0. , -0.1],\n       [-0.1, -0.1],\n       [-0.1,  0. ],\n       [ 0. , -0.2],\n       [-0.2, -0.1],\n       [-0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. , -0.1],\n       [-0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. , -0.1],\n       [-0.1,  0. ],\n       [ 0. ,  0.1],\n       [ 0.1,  0. ],\n       [ 0. ,  0.1],\n       [ 0.1,  0.1],\n       [ 0.1,  0. ],\n       [ 0. ,  0.1],\n       [ 0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. , -0.1],\n       [-0.1, -0.1],\n       [-0.1,  0. ],\n       [ 0. , -0.1],\n       [-0.1, -0.1],\n       [-0.1, -0.1],\n       [-0.1,  0. ],\n       [ 0. , -0.1],\n       [-0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. , -0.1],\n       [-0.1,  0.1],\n       [ 0.1,  0.1],\n       [ 0.1,  0.1],\n       [ 0.1,  0.1],\n       [ 0.1,  0.1],\n       [ 0.1,  0.1],\n       [ 0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0.1],\n       [ 0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0.1],\n       [ 0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0.1],\n       [ 0.1,  0. ],\n       [ 0. ,  0.1],\n       [ 0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0.1],\n       [ 0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0.1],\n       [ 0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. , -0.1],\n       [-0.1,  0.1],\n       [ 0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0.1],\n       [ 0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. , -0.1],\n       [-0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. , -0.1],\n       [-0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0.1],\n       [ 0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0.1],\n       [ 0.1, -0.1],\n       [-0.1,  0. ],\n       [ 0. ,  0.1],\n       [ 0.1,  0. ],\n       [ 0. ,  0. ],\n       [ 0. ,  0.1],\n       [ 0.1,  0.1],\n       [ 0.1,  0.1]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transform Time Series to Scale (=Normalisation ?!)\n",
    "The default activation function for LSTMs is the hyperbolic tangent (tanh) which outputs values between -1 and 1. We use MinMaxScaler class to reshape out data to this scale. To make the experiment fair, we only consider the training data for the min and max values. Otherwise, we would contaminate the experiment with knowledge from the test data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train))\n",
    "print(type(test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "     # fit scaler\n",
    "     scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "     scaler = scaler.fit(train)\n",
    "     # transform train\n",
    "     train = train.reshape(train.shape[0], train.shape[1])\n",
    "     train_scaled = scaler.transform(train)\n",
    "     # transform test\n",
    "     test = test.reshape(test.shape[0], test.shape[1])\n",
    "     test_scaled = scaler.transform(test)\n",
    "     return scaler, train_scaled, test_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "     new_row = [x for x in X] + [value]\n",
    "     array = np.array(new_row)\n",
    "     array = array.reshape(1, len(array))\n",
    "     inverted = scaler.inverse_transform(array)\n",
    "     return inverted[0, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "scaler, train_scaled, test_scaled = scale(train, test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       ...,\n       [ 0.12, -0.04],\n       [-0.04,  0.04],\n       [ 0.04, -0.04]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.04,  0.12],\n       [ 0.12,  0.04],\n       [ 0.04, -0.04],\n       [-0.04,  0.04],\n       [ 0.04, -0.04],\n       [-0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04, -0.04],\n       [-0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04, -0.04],\n       [-0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04, -0.04],\n       [-0.04,  0.04],\n       [ 0.04, -0.04],\n       [-0.04, -0.04],\n       [-0.04,  0.04],\n       [ 0.04, -0.12],\n       [-0.12, -0.04],\n       [-0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04, -0.04],\n       [-0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04, -0.04],\n       [-0.04,  0.04],\n       [ 0.04,  0.12],\n       [ 0.12,  0.04],\n       [ 0.04,  0.12],\n       [ 0.12,  0.12],\n       [ 0.12,  0.04],\n       [ 0.04,  0.12],\n       [ 0.12,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04, -0.04],\n       [-0.04, -0.04],\n       [-0.04,  0.04],\n       [ 0.04, -0.04],\n       [-0.04, -0.04],\n       [-0.04, -0.04],\n       [-0.04,  0.04],\n       [ 0.04, -0.04],\n       [-0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04, -0.04],\n       [-0.04,  0.12],\n       [ 0.12,  0.12],\n       [ 0.12,  0.12],\n       [ 0.12,  0.12],\n       [ 0.12,  0.12],\n       [ 0.12,  0.12],\n       [ 0.12,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.12],\n       [ 0.12,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.12],\n       [ 0.12,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.12],\n       [ 0.12,  0.04],\n       [ 0.04,  0.12],\n       [ 0.12,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.12],\n       [ 0.12,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.12],\n       [ 0.12,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04, -0.04],\n       [-0.04,  0.12],\n       [ 0.12,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.12],\n       [ 0.12,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04, -0.04],\n       [-0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04, -0.04],\n       [-0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.12],\n       [ 0.12,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.12],\n       [ 0.12, -0.04],\n       [-0.04,  0.04],\n       [ 0.04,  0.12],\n       [ 0.12,  0.04],\n       [ 0.04,  0.04],\n       [ 0.04,  0.12],\n       [ 0.12,  0.12],\n       [ 0.12,  0.12]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LSTM Model\n",
    "\n",
    "The LSTM layer expects input to be in a matrix with the dimensions: [samples, time steps, features].\n",
    "\n",
    "Samples: independent observations i.e. rows of data\n",
    "Time steps: ???\n",
    "Features: number of features (in this case 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# TODO: understand this in more detail!\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "     X, y = train[:, 0:-1], train[:, -1]\n",
    "     X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "     model = Sequential()\n",
    "     model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "     model.add(Dense(1))\n",
    "     model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "     for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "     return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "     X = X.reshape(1, 1, len(X))\n",
    "     yhat = model.predict(X, batch_size=batch_size)\n",
    "     return yhat[0,0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 21:36:08.412268: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# repeat experiment\n",
    "#repeats = 5\n",
    "#error_scores = list()\n",
    "#for r in range(repeats):\n",
    "#print(\"Repeat #\", r)\n",
    "# fit the model\n",
    "#lstm_model = fit_lstm(train_scaled, 1, 200, 50)    #training data, batch size, epochs, #neurons\n",
    "lstm_model = fit_lstm(train_scaled, 1, 2, 5)    #training data, batch size, epochs, #neurons"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[ 0.04]],\n\n       [[ 0.04]],\n\n       [[ 0.04]],\n\n       ...,\n\n       [[ 0.12]],\n\n       [[-0.04]],\n\n       [[ 0.04]]])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forecast the entire training dataset to build up state for forecasting\n",
    "train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "train_reshaped"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8591/8591 [==============================] - 3s 340us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.02328026],\n       [0.02234987],\n       [0.02189929],\n       ...,\n       [0.0259742 ],\n       [0.02236029],\n       [0.02322393]], dtype=float32)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.predict(train_reshaped, batch_size=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "(1,)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scaled[0, 0:-1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8591/8591 [==============================] - 3s 339us/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "MAE:  0.04423395445891926\n",
      "MSE:  0.003429429850092122\n"
     ]
    }
   ],
   "source": [
    "# walk-forward validation on the test data\n",
    "predictions = list()\n",
    "for i in range(len(test_scaled)):\n",
    "    # make one-step forecast\n",
    "    X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "    yhat = forecast_lstm(lstm_model, 1, X)  #yhat = predictioned y\n",
    "    # invert scaling\n",
    "    yhat = invert_scale(scaler, X, yhat)\n",
    "    # invert differencing\n",
    "    yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "    # store forecast\n",
    "    predictions.append(yhat)\n",
    "\n",
    "# report performance\n",
    "mae = mean_absolute_error(raw_values[-test_hours:], predictions)\n",
    "mse = mean_squared_error(raw_values[-test_hours:], predictions)\n",
    "print('MAE: ', mae)\n",
    "print('MSE: ', mse)\n",
    "#error_scores.append(rmse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "took about 20 min to train ...."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(predictions, label=\"Prediction\")\n",
    "plt.plot(raw_values[-test_hours:], label=\"Ground Truth\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.title(\"LSTM Prediction\")\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "print('MAE: ', mae)\n",
    "print('MSE: ', mse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}