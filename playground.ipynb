{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TEST PLAYGROUND\n",
    "#Just for dev puproses!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import myLibrary as mL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "DP = mL.DataProcessor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                     WDIR_42001  WSPD_42001  PRES_42001  ATMP_42001  \\\n2002-01-01 00:00:00        66.0         9.3      1017.1        22.3   \n2002-01-01 01:00:00        66.0         9.3      1017.1        22.3   \n2002-01-01 02:00:00        67.0         9.4      1017.2        21.9   \n2002-01-01 03:00:00        69.0         9.1      1017.2        22.4   \n2002-01-01 04:00:00        70.0         9.0      1017.1        22.5   \n...                         ...         ...         ...         ...   \n2022-12-31 19:00:00       195.0         0.5      1015.0        25.6   \n2022-12-31 20:00:00       210.0         1.0      1015.0        25.3   \n2022-12-31 21:00:00       231.0         0.6      1014.7        26.4   \n2022-12-31 22:00:00        18.0         0.7      1014.9        25.4   \n2022-12-31 23:00:00        68.0         1.6      1015.0        25.0   \n\n                     WTMP_42001  DEWP_42001  WDIR_42002  WSPD_42002  \\\n2002-01-01 00:00:00        25.5        16.8        39.0        10.5   \n2002-01-01 01:00:00        25.5        16.8        39.0        10.5   \n2002-01-01 02:00:00        25.5        16.6        36.0        10.9   \n2002-01-01 03:00:00        25.5        16.9        32.0        12.7   \n2002-01-01 04:00:00        25.5        16.3        33.0        12.7   \n...                         ...         ...         ...         ...   \n2022-12-31 19:00:00        24.7        24.5        22.0         0.6   \n2022-12-31 20:00:00        24.5        24.3        88.0         1.2   \n2022-12-31 21:00:00        24.7        24.4        87.0         1.7   \n2022-12-31 22:00:00        24.7        24.1        90.0         2.5   \n2022-12-31 23:00:00        24.5        24.3       116.0         3.7   \n\n                     PRES_42002  ATMP_42002  ...  WDIR_42039_ERA5  \\\n2002-01-01 00:00:00      1016.1        21.7  ...       246.007357   \n2002-01-01 01:00:00      1016.1        21.7  ...       247.678051   \n2002-01-01 02:00:00      1016.1        21.7  ...       250.591891   \n2002-01-01 03:00:00      1015.9        20.8  ...       253.468273   \n2002-01-01 04:00:00      1015.8        21.0  ...       251.493918   \n...                         ...         ...  ...              ...   \n2022-12-31 19:00:00      1015.9        25.1  ...        28.180851   \n2022-12-31 20:00:00      1015.4        24.7  ...        22.969408   \n2022-12-31 21:00:00      1014.9        24.6  ...        14.655430   \n2022-12-31 22:00:00      1014.9        24.5  ...        20.371840   \n2022-12-31 23:00:00      1015.0        24.5  ...        21.918165   \n\n                     WSPD_42039_ERA5  ATMP_42039_ERA5  WSPD_42035_ERA5  \\\n2002-01-01 00:00:00         5.756333        13.882608         8.031200   \n2002-01-01 01:00:00         5.579721        14.020573         8.216895   \n2002-01-01 02:00:00         5.582730        14.070538         8.454808   \n2002-01-01 03:00:00         5.633966        14.058979         8.471692   \n2002-01-01 04:00:00         5.638108        13.986641         8.698506   \n...                              ...              ...              ...   \n2022-12-31 19:00:00         8.602918        22.730194         2.533178   \n2022-12-31 20:00:00         7.734290        22.564177         2.669909   \n2022-12-31 21:00:00         6.485218        22.377552         3.147255   \n2022-12-31 22:00:00         3.294807        24.068445         3.469271   \n2022-12-31 23:00:00         2.229422        23.926533         3.938095   \n\n                     WSPD_42001_ERA5  DEWP_42020_ERA5  ATMP_42019_ERA5  \\\n2002-01-01 00:00:00         9.867456        10.834305        11.708612   \n2002-01-01 01:00:00         9.782997        10.975658        11.926516   \n2002-01-01 02:00:00         9.517146        11.111871        12.166319   \n2002-01-01 03:00:00         8.911373        11.239089        12.361607   \n2002-01-01 04:00:00         8.481407        11.332468        12.482585   \n...                              ...              ...              ...   \n2022-12-31 19:00:00         0.601025        19.323104        21.847184   \n2022-12-31 20:00:00         0.979714        19.245361        22.052563   \n2022-12-31 21:00:00         2.067327        19.338348        22.260412   \n2022-12-31 22:00:00         1.554299        18.567779        22.101541   \n2022-12-31 23:00:00         2.206784        18.779285        22.243125   \n\n                     WTMP_42039_ERA5  WSPD_42002_ERA5  PRES_42039_ERA5  \n2002-01-01 00:00:00        21.781113         9.820263      1019.426223  \n2002-01-01 01:00:00        21.781113        10.465795      1019.792677  \n2002-01-01 02:00:00        21.781113        11.760698      1019.725358  \n2002-01-01 03:00:00        21.781113        11.910608      1019.833394  \n2002-01-01 04:00:00        21.781113        11.716782      1019.804620  \n...                              ...              ...              ...  \n2022-12-31 19:00:00        24.392457         1.062895      1016.581840  \n2022-12-31 20:00:00        24.392457         1.330008      1016.363260  \n2022-12-31 21:00:00        24.392457         1.770915      1016.186435  \n2022-12-31 22:00:00        24.885927         2.483432      1017.067575  \n2022-12-31 23:00:00        24.885927         3.242142      1017.021132  \n\n[184080 rows x 104 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WDIR_42001</th>\n      <th>WSPD_42001</th>\n      <th>PRES_42001</th>\n      <th>ATMP_42001</th>\n      <th>WTMP_42001</th>\n      <th>DEWP_42001</th>\n      <th>WDIR_42002</th>\n      <th>WSPD_42002</th>\n      <th>PRES_42002</th>\n      <th>ATMP_42002</th>\n      <th>...</th>\n      <th>WDIR_42039_ERA5</th>\n      <th>WSPD_42039_ERA5</th>\n      <th>ATMP_42039_ERA5</th>\n      <th>WSPD_42035_ERA5</th>\n      <th>WSPD_42001_ERA5</th>\n      <th>DEWP_42020_ERA5</th>\n      <th>ATMP_42019_ERA5</th>\n      <th>WTMP_42039_ERA5</th>\n      <th>WSPD_42002_ERA5</th>\n      <th>PRES_42039_ERA5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2002-01-01 00:00:00</th>\n      <td>66.0</td>\n      <td>9.3</td>\n      <td>1017.1</td>\n      <td>22.3</td>\n      <td>25.5</td>\n      <td>16.8</td>\n      <td>39.0</td>\n      <td>10.5</td>\n      <td>1016.1</td>\n      <td>21.7</td>\n      <td>...</td>\n      <td>246.007357</td>\n      <td>5.756333</td>\n      <td>13.882608</td>\n      <td>8.031200</td>\n      <td>9.867456</td>\n      <td>10.834305</td>\n      <td>11.708612</td>\n      <td>21.781113</td>\n      <td>9.820263</td>\n      <td>1019.426223</td>\n    </tr>\n    <tr>\n      <th>2002-01-01 01:00:00</th>\n      <td>66.0</td>\n      <td>9.3</td>\n      <td>1017.1</td>\n      <td>22.3</td>\n      <td>25.5</td>\n      <td>16.8</td>\n      <td>39.0</td>\n      <td>10.5</td>\n      <td>1016.1</td>\n      <td>21.7</td>\n      <td>...</td>\n      <td>247.678051</td>\n      <td>5.579721</td>\n      <td>14.020573</td>\n      <td>8.216895</td>\n      <td>9.782997</td>\n      <td>10.975658</td>\n      <td>11.926516</td>\n      <td>21.781113</td>\n      <td>10.465795</td>\n      <td>1019.792677</td>\n    </tr>\n    <tr>\n      <th>2002-01-01 02:00:00</th>\n      <td>67.0</td>\n      <td>9.4</td>\n      <td>1017.2</td>\n      <td>21.9</td>\n      <td>25.5</td>\n      <td>16.6</td>\n      <td>36.0</td>\n      <td>10.9</td>\n      <td>1016.1</td>\n      <td>21.7</td>\n      <td>...</td>\n      <td>250.591891</td>\n      <td>5.582730</td>\n      <td>14.070538</td>\n      <td>8.454808</td>\n      <td>9.517146</td>\n      <td>11.111871</td>\n      <td>12.166319</td>\n      <td>21.781113</td>\n      <td>11.760698</td>\n      <td>1019.725358</td>\n    </tr>\n    <tr>\n      <th>2002-01-01 03:00:00</th>\n      <td>69.0</td>\n      <td>9.1</td>\n      <td>1017.2</td>\n      <td>22.4</td>\n      <td>25.5</td>\n      <td>16.9</td>\n      <td>32.0</td>\n      <td>12.7</td>\n      <td>1015.9</td>\n      <td>20.8</td>\n      <td>...</td>\n      <td>253.468273</td>\n      <td>5.633966</td>\n      <td>14.058979</td>\n      <td>8.471692</td>\n      <td>8.911373</td>\n      <td>11.239089</td>\n      <td>12.361607</td>\n      <td>21.781113</td>\n      <td>11.910608</td>\n      <td>1019.833394</td>\n    </tr>\n    <tr>\n      <th>2002-01-01 04:00:00</th>\n      <td>70.0</td>\n      <td>9.0</td>\n      <td>1017.1</td>\n      <td>22.5</td>\n      <td>25.5</td>\n      <td>16.3</td>\n      <td>33.0</td>\n      <td>12.7</td>\n      <td>1015.8</td>\n      <td>21.0</td>\n      <td>...</td>\n      <td>251.493918</td>\n      <td>5.638108</td>\n      <td>13.986641</td>\n      <td>8.698506</td>\n      <td>8.481407</td>\n      <td>11.332468</td>\n      <td>12.482585</td>\n      <td>21.781113</td>\n      <td>11.716782</td>\n      <td>1019.804620</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2022-12-31 19:00:00</th>\n      <td>195.0</td>\n      <td>0.5</td>\n      <td>1015.0</td>\n      <td>25.6</td>\n      <td>24.7</td>\n      <td>24.5</td>\n      <td>22.0</td>\n      <td>0.6</td>\n      <td>1015.9</td>\n      <td>25.1</td>\n      <td>...</td>\n      <td>28.180851</td>\n      <td>8.602918</td>\n      <td>22.730194</td>\n      <td>2.533178</td>\n      <td>0.601025</td>\n      <td>19.323104</td>\n      <td>21.847184</td>\n      <td>24.392457</td>\n      <td>1.062895</td>\n      <td>1016.581840</td>\n    </tr>\n    <tr>\n      <th>2022-12-31 20:00:00</th>\n      <td>210.0</td>\n      <td>1.0</td>\n      <td>1015.0</td>\n      <td>25.3</td>\n      <td>24.5</td>\n      <td>24.3</td>\n      <td>88.0</td>\n      <td>1.2</td>\n      <td>1015.4</td>\n      <td>24.7</td>\n      <td>...</td>\n      <td>22.969408</td>\n      <td>7.734290</td>\n      <td>22.564177</td>\n      <td>2.669909</td>\n      <td>0.979714</td>\n      <td>19.245361</td>\n      <td>22.052563</td>\n      <td>24.392457</td>\n      <td>1.330008</td>\n      <td>1016.363260</td>\n    </tr>\n    <tr>\n      <th>2022-12-31 21:00:00</th>\n      <td>231.0</td>\n      <td>0.6</td>\n      <td>1014.7</td>\n      <td>26.4</td>\n      <td>24.7</td>\n      <td>24.4</td>\n      <td>87.0</td>\n      <td>1.7</td>\n      <td>1014.9</td>\n      <td>24.6</td>\n      <td>...</td>\n      <td>14.655430</td>\n      <td>6.485218</td>\n      <td>22.377552</td>\n      <td>3.147255</td>\n      <td>2.067327</td>\n      <td>19.338348</td>\n      <td>22.260412</td>\n      <td>24.392457</td>\n      <td>1.770915</td>\n      <td>1016.186435</td>\n    </tr>\n    <tr>\n      <th>2022-12-31 22:00:00</th>\n      <td>18.0</td>\n      <td>0.7</td>\n      <td>1014.9</td>\n      <td>25.4</td>\n      <td>24.7</td>\n      <td>24.1</td>\n      <td>90.0</td>\n      <td>2.5</td>\n      <td>1014.9</td>\n      <td>24.5</td>\n      <td>...</td>\n      <td>20.371840</td>\n      <td>3.294807</td>\n      <td>24.068445</td>\n      <td>3.469271</td>\n      <td>1.554299</td>\n      <td>18.567779</td>\n      <td>22.101541</td>\n      <td>24.885927</td>\n      <td>2.483432</td>\n      <td>1017.067575</td>\n    </tr>\n    <tr>\n      <th>2022-12-31 23:00:00</th>\n      <td>68.0</td>\n      <td>1.6</td>\n      <td>1015.0</td>\n      <td>25.0</td>\n      <td>24.5</td>\n      <td>24.3</td>\n      <td>116.0</td>\n      <td>3.7</td>\n      <td>1015.0</td>\n      <td>24.5</td>\n      <td>...</td>\n      <td>21.918165</td>\n      <td>2.229422</td>\n      <td>23.926533</td>\n      <td>3.938095</td>\n      <td>2.206784</td>\n      <td>18.779285</td>\n      <td>22.243125</td>\n      <td>24.885927</td>\n      <td>3.242142</td>\n      <td>1017.021132</td>\n    </tr>\n  </tbody>\n</table>\n<p>184080 rows × 104 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATAFILE = \"dataset_GOM_1_A_A.pickle\"\n",
    "with open(f'data/datasets/type_A/{DATAFILE}', 'rb') as f:\n",
    "    # load the object from the file using pickle.load()\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "data = dataset[\"data\"]\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#TEST DATA FOR WIND SPEED\n",
    "# n = 1000\n",
    "#\n",
    "# data = {}\n",
    "# for col in range(1, 5):\n",
    "#     key = f'WDIR_{col}' if col % 2 != 0 else f'WSPD_{col}'\n",
    "#     data[key] = []\n",
    "#\n",
    "#     for row in range(1, n+1):\n",
    "#         value = (row-1) * 4 + col\n",
    "#         data[key].append(value)\n",
    "#\n",
    "# timestamps = pd.date_range(start='2020-01-01 01:00:00', periods=n, freq='H')\n",
    "# data = pd.DataFrame(data, index=timestamps)\n",
    "# data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# TEST DATA FOR CUSTOM LOSS FUNCTION\n",
    "# n = 1000  # Number of rows\n",
    "#\n",
    "# data = {\n",
    "#     'WDIR_1': [1.1] * n,\n",
    "#     'WSPD_1': [1.2] * n,\n",
    "#     'WDIR_2': [2.1] * n,\n",
    "#     'WSPD_2': [2.2] * n,\n",
    "#     'WDIR_1_ERA5': [100.1] * n,\n",
    "#     'WSPD_1_ERA5': [100.2] * n,\n",
    "#     'WDIR_2_ERA5': [200.1] * n,\n",
    "#     'WSPD_2_ERA5': [200.2] * n\n",
    "# }\n",
    "#\n",
    "# timestamps = pd.date_range(start='2020-01-01 01:00:00', periods=n, freq='H')\n",
    "# data = pd.DataFrame(data, index=timestamps)\n",
    "# data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                     WDIR_42001(t-3)  WSPD_42001(t-3)  PRES_42001(t-3)  \\\n2002-01-01 03:00:00             66.0              9.3           1017.1   \n2002-01-01 04:00:00             66.0              9.3           1017.1   \n2002-01-01 05:00:00             67.0              9.4           1017.2   \n2002-01-01 06:00:00             69.0              9.1           1017.2   \n2002-01-01 07:00:00             70.0              9.0           1017.1   \n...                              ...              ...              ...   \n2022-12-31 19:00:00            124.0              0.8           1017.1   \n2022-12-31 20:00:00            107.0              1.1           1016.6   \n2022-12-31 21:00:00            147.0              1.1           1015.9   \n2022-12-31 22:00:00            195.0              0.5           1015.0   \n2022-12-31 23:00:00            210.0              1.0           1015.0   \n\n                     ATMP_42001(t-3)  WTMP_42001(t-3)  DEWP_42001(t-3)  \\\n2002-01-01 03:00:00             22.3             25.5             16.8   \n2002-01-01 04:00:00             22.3             25.5             16.8   \n2002-01-01 05:00:00             21.9             25.5             16.6   \n2002-01-01 06:00:00             22.4             25.5             16.9   \n2002-01-01 07:00:00             22.5             25.5             16.3   \n...                              ...              ...              ...   \n2022-12-31 19:00:00             24.6             24.4             23.8   \n2022-12-31 20:00:00             24.9             24.4             23.9   \n2022-12-31 21:00:00             25.1             24.5             24.3   \n2022-12-31 22:00:00             25.6             24.7             24.5   \n2022-12-31 23:00:00             25.3             24.5             24.3   \n\n                     WDIR_42002(t-3)  WSPD_42002(t-3)  PRES_42002(t-3)  \\\n2002-01-01 03:00:00             39.0             10.5           1016.1   \n2002-01-01 04:00:00             39.0             10.5           1016.1   \n2002-01-01 05:00:00             36.0             10.9           1016.1   \n2002-01-01 06:00:00             32.0             12.7           1015.9   \n2002-01-01 07:00:00             33.0             12.7           1015.8   \n...                              ...              ...              ...   \n2022-12-31 19:00:00            316.0              1.3           1017.8   \n2022-12-31 20:00:00            104.0              0.0           1017.7   \n2022-12-31 21:00:00             42.0              0.5           1016.8   \n2022-12-31 22:00:00             22.0              0.6           1015.9   \n2022-12-31 23:00:00             88.0              1.2           1015.4   \n\n                     ATMP_42002(t-3)  ...  WDIR_42039_ERA5(t)  \\\n2002-01-01 03:00:00             21.7  ...          253.468273   \n2002-01-01 04:00:00             21.7  ...          251.493918   \n2002-01-01 05:00:00             21.7  ...          247.676567   \n2002-01-01 06:00:00             20.8  ...          249.327228   \n2002-01-01 07:00:00             21.0  ...          249.422157   \n...                              ...  ...                 ...   \n2022-12-31 19:00:00             24.7  ...           28.180851   \n2022-12-31 20:00:00             25.8  ...           22.969408   \n2022-12-31 21:00:00             25.5  ...           14.655430   \n2022-12-31 22:00:00             25.1  ...           20.371840   \n2022-12-31 23:00:00             24.7  ...           21.918165   \n\n                     WSPD_42039_ERA5(t)  ATMP_42039_ERA5(t)  \\\n2002-01-01 03:00:00            5.633966           14.058979   \n2002-01-01 04:00:00            5.638108           13.986641   \n2002-01-01 05:00:00            5.438761           13.804677   \n2002-01-01 06:00:00            5.617903           13.556713   \n2002-01-01 07:00:00            5.999083           13.194649   \n...                                 ...                 ...   \n2022-12-31 19:00:00            8.602918           22.730194   \n2022-12-31 20:00:00            7.734290           22.564177   \n2022-12-31 21:00:00            6.485218           22.377552   \n2022-12-31 22:00:00            3.294807           24.068445   \n2022-12-31 23:00:00            2.229422           23.926533   \n\n                     WSPD_42035_ERA5(t)  WSPD_42001_ERA5(t)  \\\n2002-01-01 03:00:00            8.471692            8.911373   \n2002-01-01 04:00:00            8.698506            8.481407   \n2002-01-01 05:00:00            8.898239            8.035067   \n2002-01-01 06:00:00            9.086013            8.451408   \n2002-01-01 07:00:00            9.266253            8.955747   \n...                                 ...                 ...   \n2022-12-31 19:00:00            2.533178            0.601025   \n2022-12-31 20:00:00            2.669909            0.979714   \n2022-12-31 21:00:00            3.147255            2.067327   \n2022-12-31 22:00:00            3.469271            1.554299   \n2022-12-31 23:00:00            3.938095            2.206784   \n\n                     DEWP_42020_ERA5(t)  ATMP_42019_ERA5(t)  \\\n2002-01-01 03:00:00           11.239089           12.361607   \n2002-01-01 04:00:00           11.332468           12.482585   \n2002-01-01 05:00:00           11.430130           12.548997   \n2002-01-01 06:00:00           11.504233           12.615050   \n2002-01-01 07:00:00           11.601895           12.729567   \n...                                 ...                 ...   \n2022-12-31 19:00:00           19.323104           21.847184   \n2022-12-31 20:00:00           19.245361           22.052563   \n2022-12-31 21:00:00           19.338348           22.260412   \n2022-12-31 22:00:00           18.567779           22.101541   \n2022-12-31 23:00:00           18.779285           22.243125   \n\n                     WTMP_42039_ERA5(t)  WSPD_42002_ERA5(t)  \\\n2002-01-01 03:00:00           21.781113           11.910608   \n2002-01-01 04:00:00           21.781113           11.716782   \n2002-01-01 05:00:00           21.781113           11.294205   \n2002-01-01 06:00:00           21.781113           10.893404   \n2002-01-01 07:00:00           21.781113            9.970325   \n...                                 ...                 ...   \n2022-12-31 19:00:00           24.392457            1.062895   \n2022-12-31 20:00:00           24.392457            1.330008   \n2022-12-31 21:00:00           24.392457            1.770915   \n2022-12-31 22:00:00           24.885927            2.483432   \n2022-12-31 23:00:00           24.885927            3.242142   \n\n                     PRES_42039_ERA5(t)  \n2002-01-01 03:00:00         1019.833394  \n2002-01-01 04:00:00         1019.804620  \n2002-01-01 05:00:00         1019.716671  \n2002-01-01 06:00:00         1020.098869  \n2002-01-01 07:00:00         1020.017435  \n...                                 ...  \n2022-12-31 19:00:00         1016.581840  \n2022-12-31 20:00:00         1016.363260  \n2022-12-31 21:00:00         1016.186435  \n2022-12-31 22:00:00         1017.067575  \n2022-12-31 23:00:00         1017.021132  \n\n[184077 rows x 416 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WDIR_42001(t-3)</th>\n      <th>WSPD_42001(t-3)</th>\n      <th>PRES_42001(t-3)</th>\n      <th>ATMP_42001(t-3)</th>\n      <th>WTMP_42001(t-3)</th>\n      <th>DEWP_42001(t-3)</th>\n      <th>WDIR_42002(t-3)</th>\n      <th>WSPD_42002(t-3)</th>\n      <th>PRES_42002(t-3)</th>\n      <th>ATMP_42002(t-3)</th>\n      <th>...</th>\n      <th>WDIR_42039_ERA5(t)</th>\n      <th>WSPD_42039_ERA5(t)</th>\n      <th>ATMP_42039_ERA5(t)</th>\n      <th>WSPD_42035_ERA5(t)</th>\n      <th>WSPD_42001_ERA5(t)</th>\n      <th>DEWP_42020_ERA5(t)</th>\n      <th>ATMP_42019_ERA5(t)</th>\n      <th>WTMP_42039_ERA5(t)</th>\n      <th>WSPD_42002_ERA5(t)</th>\n      <th>PRES_42039_ERA5(t)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2002-01-01 03:00:00</th>\n      <td>66.0</td>\n      <td>9.3</td>\n      <td>1017.1</td>\n      <td>22.3</td>\n      <td>25.5</td>\n      <td>16.8</td>\n      <td>39.0</td>\n      <td>10.5</td>\n      <td>1016.1</td>\n      <td>21.7</td>\n      <td>...</td>\n      <td>253.468273</td>\n      <td>5.633966</td>\n      <td>14.058979</td>\n      <td>8.471692</td>\n      <td>8.911373</td>\n      <td>11.239089</td>\n      <td>12.361607</td>\n      <td>21.781113</td>\n      <td>11.910608</td>\n      <td>1019.833394</td>\n    </tr>\n    <tr>\n      <th>2002-01-01 04:00:00</th>\n      <td>66.0</td>\n      <td>9.3</td>\n      <td>1017.1</td>\n      <td>22.3</td>\n      <td>25.5</td>\n      <td>16.8</td>\n      <td>39.0</td>\n      <td>10.5</td>\n      <td>1016.1</td>\n      <td>21.7</td>\n      <td>...</td>\n      <td>251.493918</td>\n      <td>5.638108</td>\n      <td>13.986641</td>\n      <td>8.698506</td>\n      <td>8.481407</td>\n      <td>11.332468</td>\n      <td>12.482585</td>\n      <td>21.781113</td>\n      <td>11.716782</td>\n      <td>1019.804620</td>\n    </tr>\n    <tr>\n      <th>2002-01-01 05:00:00</th>\n      <td>67.0</td>\n      <td>9.4</td>\n      <td>1017.2</td>\n      <td>21.9</td>\n      <td>25.5</td>\n      <td>16.6</td>\n      <td>36.0</td>\n      <td>10.9</td>\n      <td>1016.1</td>\n      <td>21.7</td>\n      <td>...</td>\n      <td>247.676567</td>\n      <td>5.438761</td>\n      <td>13.804677</td>\n      <td>8.898239</td>\n      <td>8.035067</td>\n      <td>11.430130</td>\n      <td>12.548997</td>\n      <td>21.781113</td>\n      <td>11.294205</td>\n      <td>1019.716671</td>\n    </tr>\n    <tr>\n      <th>2002-01-01 06:00:00</th>\n      <td>69.0</td>\n      <td>9.1</td>\n      <td>1017.2</td>\n      <td>22.4</td>\n      <td>25.5</td>\n      <td>16.9</td>\n      <td>32.0</td>\n      <td>12.7</td>\n      <td>1015.9</td>\n      <td>20.8</td>\n      <td>...</td>\n      <td>249.327228</td>\n      <td>5.617903</td>\n      <td>13.556713</td>\n      <td>9.086013</td>\n      <td>8.451408</td>\n      <td>11.504233</td>\n      <td>12.615050</td>\n      <td>21.781113</td>\n      <td>10.893404</td>\n      <td>1020.098869</td>\n    </tr>\n    <tr>\n      <th>2002-01-01 07:00:00</th>\n      <td>70.0</td>\n      <td>9.0</td>\n      <td>1017.1</td>\n      <td>22.5</td>\n      <td>25.5</td>\n      <td>16.3</td>\n      <td>33.0</td>\n      <td>12.7</td>\n      <td>1015.8</td>\n      <td>21.0</td>\n      <td>...</td>\n      <td>249.422157</td>\n      <td>5.999083</td>\n      <td>13.194649</td>\n      <td>9.266253</td>\n      <td>8.955747</td>\n      <td>11.601895</td>\n      <td>12.729567</td>\n      <td>21.781113</td>\n      <td>9.970325</td>\n      <td>1020.017435</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2022-12-31 19:00:00</th>\n      <td>124.0</td>\n      <td>0.8</td>\n      <td>1017.1</td>\n      <td>24.6</td>\n      <td>24.4</td>\n      <td>23.8</td>\n      <td>316.0</td>\n      <td>1.3</td>\n      <td>1017.8</td>\n      <td>24.7</td>\n      <td>...</td>\n      <td>28.180851</td>\n      <td>8.602918</td>\n      <td>22.730194</td>\n      <td>2.533178</td>\n      <td>0.601025</td>\n      <td>19.323104</td>\n      <td>21.847184</td>\n      <td>24.392457</td>\n      <td>1.062895</td>\n      <td>1016.581840</td>\n    </tr>\n    <tr>\n      <th>2022-12-31 20:00:00</th>\n      <td>107.0</td>\n      <td>1.1</td>\n      <td>1016.6</td>\n      <td>24.9</td>\n      <td>24.4</td>\n      <td>23.9</td>\n      <td>104.0</td>\n      <td>0.0</td>\n      <td>1017.7</td>\n      <td>25.8</td>\n      <td>...</td>\n      <td>22.969408</td>\n      <td>7.734290</td>\n      <td>22.564177</td>\n      <td>2.669909</td>\n      <td>0.979714</td>\n      <td>19.245361</td>\n      <td>22.052563</td>\n      <td>24.392457</td>\n      <td>1.330008</td>\n      <td>1016.363260</td>\n    </tr>\n    <tr>\n      <th>2022-12-31 21:00:00</th>\n      <td>147.0</td>\n      <td>1.1</td>\n      <td>1015.9</td>\n      <td>25.1</td>\n      <td>24.5</td>\n      <td>24.3</td>\n      <td>42.0</td>\n      <td>0.5</td>\n      <td>1016.8</td>\n      <td>25.5</td>\n      <td>...</td>\n      <td>14.655430</td>\n      <td>6.485218</td>\n      <td>22.377552</td>\n      <td>3.147255</td>\n      <td>2.067327</td>\n      <td>19.338348</td>\n      <td>22.260412</td>\n      <td>24.392457</td>\n      <td>1.770915</td>\n      <td>1016.186435</td>\n    </tr>\n    <tr>\n      <th>2022-12-31 22:00:00</th>\n      <td>195.0</td>\n      <td>0.5</td>\n      <td>1015.0</td>\n      <td>25.6</td>\n      <td>24.7</td>\n      <td>24.5</td>\n      <td>22.0</td>\n      <td>0.6</td>\n      <td>1015.9</td>\n      <td>25.1</td>\n      <td>...</td>\n      <td>20.371840</td>\n      <td>3.294807</td>\n      <td>24.068445</td>\n      <td>3.469271</td>\n      <td>1.554299</td>\n      <td>18.567779</td>\n      <td>22.101541</td>\n      <td>24.885927</td>\n      <td>2.483432</td>\n      <td>1017.067575</td>\n    </tr>\n    <tr>\n      <th>2022-12-31 23:00:00</th>\n      <td>210.0</td>\n      <td>1.0</td>\n      <td>1015.0</td>\n      <td>25.3</td>\n      <td>24.5</td>\n      <td>24.3</td>\n      <td>88.0</td>\n      <td>1.2</td>\n      <td>1015.4</td>\n      <td>24.7</td>\n      <td>...</td>\n      <td>21.918165</td>\n      <td>2.229422</td>\n      <td>23.926533</td>\n      <td>3.938095</td>\n      <td>2.206784</td>\n      <td>18.779285</td>\n      <td>22.243125</td>\n      <td>24.885927</td>\n      <td>3.242142</td>\n      <td>1017.021132</td>\n    </tr>\n  </tbody>\n</table>\n<p>184077 rows × 416 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_supervised = DP.data_to_supervised(data, n_in=3, n_out=1)\n",
    "data_supervised"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['WDIR_42001(t-3)', 'WSPD_42001(t-3)', 'PRES_42001(t-3)',\n       'ATMP_42001(t-3)', 'WTMP_42001(t-3)', 'DEWP_42001(t-3)',\n       'WDIR_42002(t-3)', 'WSPD_42002(t-3)', 'PRES_42002(t-3)',\n       'ATMP_42002(t-3)',\n       ...\n       'WDIR_42039_ERA5(t)', 'WSPD_42039_ERA5(t)', 'ATMP_42039_ERA5(t)',\n       'WSPD_42035_ERA5(t)', 'WSPD_42001_ERA5(t)', 'DEWP_42020_ERA5(t)',\n       'ATMP_42019_ERA5(t)', 'WTMP_42039_ERA5(t)', 'WSPD_42002_ERA5(t)',\n       'PRES_42039_ERA5(t)'],\n      dtype='object', length=416)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_supervised.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# NEW VERSION OF THIS METHOD !!\n",
    "def train_test_split(data: pd.DataFrame, n_test_hours: int):\n",
    "\n",
    "    # Extract time options\n",
    "    input_cols, output_cols = [], []\n",
    "    for column_header in data.columns:\n",
    "        # Split the column header by '(' and ')' to extract the time option\n",
    "        time_option = column_header.split('(')[-1].split(')')[0]\n",
    "        time_option = f\"({time_option})\"\n",
    "        if '-' in time_option and time_option not in input_cols:\n",
    "            input_cols.append(time_option)\n",
    "        # elif '-' not in time_option and time_option not in output_cols:\n",
    "        #         output_cols.append(time_option)\n",
    "\n",
    "    # split into train and test sets\n",
    "    train = data.head(-n_test_hours)\n",
    "    test = data.tail(n_test_hours)\n",
    "\n",
    "# Input X:\n",
    "    #Create list of dataframes - one dataframe per time_stamp\n",
    "    df_train_X = []\n",
    "    df_test_X = []\n",
    "    #df_train_y = []\n",
    "    #df_test_y = []\n",
    "    for time_option in input_cols:\n",
    "        df_train_X.append(train.filter(like=time_option, axis=1))\n",
    "        df_test_X.append(test.filter(like=time_option, axis=1))\n",
    "\n",
    "    # for time_option in output_cols:\n",
    "    #     df_train_y.append(train.filter(like=time_option, axis=1))\n",
    "    #     df_test_y.append(test.filter(like=time_option, axis=1))\n",
    "\n",
    "    # Get the dimensions\n",
    "    train_X_dims = (df_train_X[0].shape[0], # Number of rows\n",
    "                    len(df_train_X),        # Number of dataframes = number of timestamps\n",
    "                    df_train_X[0].shape[1]     # number of cols = number of features\n",
    "    )\n",
    "    test_X_dims = (df_test_X[0].shape[0], # Number of rows\n",
    "                    len(df_test_X),        # Number of dataframes = number of timestamps\n",
    "                    df_test_X[0].shape[1]     # number of cols = number of features\n",
    "    )\n",
    "    # train_y_dims = (df_train_y[0].shape[0], # Number of rows\n",
    "    #                 len(df_train_y),        # Number of dataframes = number of timestamps\n",
    "    #                 df_train_y[0].shape[1]     # number of cols = number of features\n",
    "    # )\n",
    "    # test_y_dims = (df_test_y[0].shape[0], # Number of rows\n",
    "    #                 len(df_test_y),        # Number of dataframes = number of timestamps\n",
    "    #                 df_test_y[0].shape[1]     # number of cols = number of features\n",
    "    # )\n",
    "\n",
    "    # Create a three-dimensional array filled with NaN\n",
    "    train_X = np.empty(train_X_dims)\n",
    "    test_X  = np.empty(test_X_dims)\n",
    "    #train_y = np.empty(train_y_dims)\n",
    "    #test_y  = np.empty(test_y_dims)\n",
    "    train_X.fill(np.nan)\n",
    "    test_X.fill(np.nan)\n",
    "    #train_y.fill(np.nan)\n",
    "    #test_y.fill(np.nan)\n",
    "\n",
    "    # Fill the array with data from dataframes\n",
    "    for i, df in enumerate(df_train_X):\n",
    "        train_X[:, i, :] = df.values\n",
    "    for i, df in enumerate(df_test_X):\n",
    "        test_X[:, i, :] = df.values\n",
    "    # for i, df in enumerate(df_train_y):\n",
    "    #     train_y[:, i, :] = df.values\n",
    "    # for i, df in enumerate(df_test_y):\n",
    "    #     test_y[:, i, :] = df.values\n",
    "\n",
    "# Output y:\n",
    "    output_cols = [i for i in range(data.values.shape[1]) if ('(t)' in data.columns[i]) or ('t+' in data.columns[i])]\n",
    "    # split into input and outputs\n",
    "    train_y = train.values[:, output_cols]\n",
    "    test_y = test.values[:, output_cols]\n",
    "\n",
    "    return train_X, train_y, test_X, test_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  69.        ,    9.1       , 1017.2       , ...,   21.78111283,\n          11.91060766, 1019.8333938 ],\n       [  70.        ,    9.        , 1017.1       , ...,   21.78111283,\n          11.71678236, 1019.80462039],\n       [  69.        ,    9.6       , 1016.5       , ...,   21.78111283,\n          11.29420489, 1019.7166715 ],\n       ...,\n       [ 178.        ,    7.1       , 1012.1       , ...,   24.19882323,\n           5.14367023, 1015.14167977],\n       [ 185.        ,    7.1       , 1012.5       , ...,   24.39245716,\n           5.04146924, 1015.23243546],\n       [ 185.        ,    5.9       , 1012.9       , ...,   24.39245716,\n           3.65117301, 1015.14636669]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = train_test_split(data_supervised, 24)\n",
    "train_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184053, 3, 104)\n",
      "(184053, 104)\n",
      "(24, 3, 104)\n",
      "(24, 104)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_45 (Conv1D)          (None, 2, 128)            26752     \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPoolin  (None, 2, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_46 (Conv1D)          (None, 1, 64)             16448     \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 104)               5304      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,754\n",
      "Trainable params: 51,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "WEIGHTED LOSS------ TYPLE:<class 'tensorflow.python.framework.ops.Tensor'>-------VALUE: Tensor(\"loss/add:0\", shape=(None,), dtype=float32)\n",
      "WEIGHTED LOSS------ TYPLE:<class 'tensorflow.python.framework.ops.Tensor'>-------VALUE: Tensor(\"loss/add:0\", shape=(None,), dtype=float32)\n",
      "2561/2589 [============================>.] - ETA: 0s - loss: 1786.9518WEIGHTED LOSS------ TYPLE:<class 'tensorflow.python.framework.ops.Tensor'>-------VALUE: Tensor(\"loss/add:0\", shape=(None,), dtype=float32)\n",
      "2589/2589 [==============================] - 6s 2ms/step - loss: 1772.4564 - val_loss: 429.9087\n",
      "Epoch 2/100\n",
      " 660/2589 [======>.......................] - ETA: 4s - loss: 447.9946"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[37], line 45\u001B[0m\n\u001B[1;32m     42\u001B[0m        \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[1;32m     44\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 45\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mModels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCNN\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_X\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[37], line 39\u001B[0m, in \u001B[0;36mModels.CNN\u001B[0;34m(train_X, train_y, alpha)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28mprint\u001B[39m(model\u001B[38;5;241m.\u001B[39msummary())\n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m# fit network\u001B[39;00m\n\u001B[0;32m---> 39\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_X\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/keras/engine/training.py:1650\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1642\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1643\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1644\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1647\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1648\u001B[0m ):\n\u001B[1;32m   1649\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1650\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1651\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1652\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    877\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    879\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 880\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    882\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    883\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    909\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    910\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    911\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 912\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    913\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    914\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    915\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    916\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    132\u001B[0m   (concrete_function,\n\u001B[1;32m    133\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m--> 134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1741\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1743\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1744\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1745\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1746\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1747\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1748\u001B[0m     args,\n\u001B[1;32m   1749\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1750\u001B[0m     executing_eagerly)\n\u001B[1;32m   1751\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    377\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 378\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    380\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    381\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    384\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    385\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    386\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    387\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    390\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    391\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Master_Project/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    " class Models():\n",
    "    def CNN(train_X, train_y, alpha):\n",
    "        def custom_loss():\n",
    "            def loss(y_true, y_pred):\n",
    "\n",
    "                # Split y_true and y_pred into two features\n",
    "                y_true_NDBC, y_true_ERA5 = tf.split(y_true, num_or_size_splits=2, axis=1)\n",
    "                y_pred_NDBC, y_pred_ERA5 = tf.split(y_pred, num_or_size_splits=2, axis=1)\n",
    "\n",
    "                # Calculate the mean squared error for each feature\n",
    "                mse_NDBC = K.mean(K.square(y_true_NDBC - y_pred_NDBC), axis=-1)\n",
    "                mse_ERA5 = K.mean(K.square(y_true_ERA5 - y_pred_ERA5), axis=-1)\n",
    "\n",
    "                # Calculate the weighted loss\n",
    "                weighted_loss = alpha * mse_NDBC + (1 - alpha) * mse_ERA5\n",
    "\n",
    "                print(f\"WEIGHTED LOSS------ TYPLE:{type(weighted_loss)}-------VALUE: {weighted_loss}\")\n",
    "                return weighted_loss\n",
    "            return loss\n",
    "\n",
    "\n",
    "        #design network\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=128, kernel_size=2, activation='relu', input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(2, 128)))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(50, activation='relu'))\n",
    "        model.add(Dense(train_y.shape[1]))\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss=custom_loss(),\n",
    "                      )\n",
    "\n",
    "        print(model.summary())\n",
    "\n",
    "        # fit network\n",
    "        history = model.fit(train_X, train_y, epochs=100, batch_size=64, verbose=1, shuffle=False,\n",
    "                            validation_split=0.1)\n",
    "\n",
    "        return model\n",
    "\n",
    "alpha = 0\n",
    "model = Models.CNN(train_X, train_y, alpha)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# model.predict(train_X, batch_size=1)\n",
    "# yhat = model.predict(test_X)\n",
    "# yhat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alpha = 0\n",
    "LSTM_model = mL.Models.get_model(\"LSTM\",train_X, train_y, alpha)\n",
    "GRU_model = mL.Models.get_model(\"GRU\",train_X, train_y, alpha)\n",
    "CNN_model = mL.Models.get_model(\"CNN\",train_X, train_y, alpha)\n",
    "TCN_model = mL.Models.get_model(\"TCN\",train_X, train_y, alpha)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "LSTM_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "GRU_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CNN_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TCN_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # design network\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "# #model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# #model.add(Dropout(0.5))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(100, activation='relu'))\n",
    "# model.add(Dense(train_y.shape[1]))\n",
    "#\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "#\n",
    "# print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#history = model.fit(train_X, train_y, epochs=100, batch_size=64, verbose=1, shuffle=False, validation_split=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model = mL.Models.get_model(\"CNN\", train_X, train_y, 0.0)\n",
    "#model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}